{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREVIOUS WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Python Imports\n",
    "import math, time, random, datetime\n",
    "from math import sqrt\n",
    "# Data Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization \n",
    "import matplotlib.pyplot as plt\n",
    "import missingno\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "# Preprocessing\n",
    "from scipy.linalg import svd\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from fancyimpute import IterativeImputer\n",
    "\n",
    "# Modelling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "sample_submission = pd.read_csv('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mice_imputation(df):\n",
    "    XY_incomplete = df\n",
    "\n",
    "    n_imputations = 5\n",
    "    XY_completed = []\n",
    "    for i in range(n_imputations):\n",
    "        imputer = IterativeImputer(n_iter=5, sample_posterior=True, random_state=i)\n",
    "        XY_completed.append(imputer.fit_transform(XY_incomplete))\n",
    "    \n",
    "    \n",
    "    return pd.DataFrame(data=XY_completed, columns=df.columns, index=df.index)\n",
    "\n",
    "def fill_missing_or_nan_values(df):\n",
    "    fill_with = 0\n",
    "    \n",
    "    # Get the most common element by using size(),\n",
    "    # which returns the element and how common it is\n",
    "    for column in df:\n",
    "        \n",
    "        # Check if the column is an object, float64 or int64\n",
    "        is_it_float = (df[column].dtype == np.float64)\n",
    "        is_it_int = (df[column].dtype == np.int64)\n",
    "        \n",
    "        # If it is an object,\n",
    "        # find the most common element and fill missing and NaN values\n",
    "        if(not is_it_float and not is_it_int):\n",
    "            fill_with = df[column].mode().item()\n",
    "                    \n",
    "        # If it is either a float64 or int64,\n",
    "        # then calculate the mean and fill missing and NaN values\n",
    "        else:\n",
    "            if is_it_float:\n",
    "                fill_with = np.nanmean(df[column], dtype=np.float64)\n",
    "            if is_it_int:\n",
    "                fill_with = np.nanmean(df[column], dtype=np.int64)\n",
    "        \n",
    "        # Fill the values in our dataset\n",
    "        df[column] = df[column].fillna(fill_with)\n",
    "        fill_with = 0\n",
    "\n",
    "def data_engineering(train, test):\n",
    "    # Concatenate all of data\n",
    "    cc_data = pd.concat([train, test])\n",
    "    cc_data = cc_data.drop(['Id', 'SalePrice','Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature'], axis=1)\n",
    "    \n",
    "    # Get the SalePrice as the natural logarithm\n",
    "    train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n",
    "    y = train['SalePrice']\n",
    "    \n",
    "    # One-Hot encode all data\n",
    "    cc_data = pd.get_dummies(cc_data, prefix_sep='_')\n",
    "    \n",
    "    #MICE Imputation\n",
    "    cc_data = mice_imputation(cc_data)\n",
    "    \n",
    "    # Fill missing or NaN values\n",
    "    #fill_missing_or_nan_values(cc_data)\n",
    "    \n",
    "    # Slice data, train.shape[0] is the observations\n",
    "    # 1) from start to middle of observations\n",
    "    # 2) from middle of observations to end\n",
    "    X_train = cc_data[:train.shape[0]]\n",
    "    X_test = cc_data[train.shape[0]:]\n",
    "    \n",
    "    return X_train,X_test,y\n",
    "\n",
    "# X is dataframe, y is output, m is how many features you want selected\n",
    "# returns array of highest scoring features\n",
    "def feature_selection(X, y, m):\n",
    "    # Data is standardized here, minus mean and divided by standard deviation\n",
    "    # The correlation between each regressor and the target is computed\n",
    "    # It is converted to an F score then to a p-value, which is returned\n",
    "    f_regression = lambda X,y : sklearn.feature_selection.f_regression(X,y,center=False)\n",
    "\n",
    "    # removes all but the  highest scoring features\n",
    "    featureSelector = SelectKBest(score_func=f_regression,k=m)\n",
    "    featureSelector.fit(X,y)\n",
    "    high_score_arr = [X.columns[1+zero_based_index] for zero_based_index in list(featureSelector.get_support(indices=True))]\n",
    "    \n",
    "    return high_score_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caspe\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:43: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-48df920326ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_engineering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;31m#selected_features = feature_selection(df_train, y, 50)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-49b4b45f40f5>\u001b[0m in \u001b[0;36mdata_engineering\u001b[1;34m(train, test)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;31m#MICE Imputation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0mcc_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmice_imputation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcc_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;31m# Fill missing or NaN values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-49b4b45f40f5>\u001b[0m in \u001b[0;36mmice_imputation\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mXY_completed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfill_missing_or_nan_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    449\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m                     mgr = init_ndarray(data, index, columns, dtype=dtype,\n\u001b[1;32m--> 451\u001b[1;33m                                        copy=copy)\n\u001b[0m\u001b[0;32m    452\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[1;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;31m# by definition an array here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;31m# the dtypes will be coerced to a single dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m     \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprep_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mprep_ndarray\u001b[1;34m(values, copy)\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Must pass 2-d input'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Must pass 2-d input"
     ]
    }
   ],
   "source": [
    "def random_forest_prediction(X_train,X_test,y_real):\n",
    "    gs = GridSearchCV(\n",
    "        estimator=RandomForestRegressor(),\n",
    "        param_grid={\n",
    "            'max_depth': [3, None],\n",
    "            'n_estimators': (10, 30, 50, 100, 200, 400, 600, 800, 1000)\n",
    "        }, cv=10, n_jobs=-1, scoring='neg_mean_squared_error'\n",
    "    )\n",
    "    model = gs.fit(X_train,y_real)\n",
    "    pred = model.predict(X_test)\n",
    "    score = sqrt(-model.best_score_)\n",
    "    \n",
    "    # return all predictions and mean of all cross validated scores\n",
    "    return pred, score\n",
    "\n",
    "df_train,df_test,y = data_engineering(train,test)\n",
    "#selected_features = feature_selection(df_train, y, 50)\n",
    "\n",
    "#pred,score = random_forest_prediction(df_train[selected_features], df_test[selected_features], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-e10c0e939d62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmissingValues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mcallMissingValues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfindMissingValues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mcallMissingValues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "def findMissingValues(df, columns):\n",
    "    \"\"\"\n",
    "    Finds number of rows where certain columns are missing values.\n",
    "    ::param_df:: = target dataframe\n",
    "    ::param_columns:: = list of columns\n",
    "    \"\"\"\n",
    "    missingValues = {}\n",
    "    print(\"Number of missing or NaN values for each column:\")\n",
    "    dfLength = len(df)\n",
    "    for column in columns:\n",
    "        totalColumnValues = df[column].value_counts().sum()\n",
    "        missingValues[column] = dfLength-totalColumnValues\n",
    "    return missingValues\n",
    "\n",
    "callMissingValues = findMissingValues(df_train, columns=df_train.columns)\n",
    "callMissingValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[126795.6940707  154247.96985992 176730.12468359 ... 162409.0399778\n",
      " 106197.57986824 240725.96555373]\n",
      "0.14861584816147727\n"
     ]
    }
   ],
   "source": [
    "# To convert prediction of SalePrice into the actual value, we take exponential value\n",
    "print(np.exp(pred))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# s can be array of functions for different models to run\\ndef kfold_cv_models(k,s):\\n    best_models_test_error = 0\\n\\n    for fold in range(k):\\n        # we have k partitions\\n        # let df_train and df_test be the next partition\\n        for model in range(s):\\n            # run next model with current k with df_train\\n            # get test error of df_test\\n            if this_models_test_error < best_models_test_error:\\n                best_models_test_error = this_models_test_error\\n    return best_models_test_error\\n'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# s can be array of functions for different models to run\n",
    "def kfold_cv_models(k,s):\n",
    "    best_models_test_error = 0\n",
    "\n",
    "    for fold in range(k):\n",
    "        # we have k partitions\n",
    "        # let df_train and df_test be the next partition\n",
    "        for model in range(s):\n",
    "            # run next model with current k with df_train\n",
    "            # get test error of df_test\n",
    "            if this_models_test_error < best_models_test_error:\n",
    "                best_models_test_error = this_models_test_error\n",
    "    return best_models_test_error\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
