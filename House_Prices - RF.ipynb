{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "t6W7PQysnFNx",
    "outputId": "4357a8cb-3582-4165-c771-e8156bcb26fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fancyimpute import IterativeImputer\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold, ParameterGrid, ParameterSampler\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "train = pd.read_csv('https://raw.githubusercontent.com/casperbh96/house-price-prediction/master/Experimental/data/train.csv')\n",
    "test = pd.read_csv('https://raw.githubusercontent.com/casperbh96/house-price-prediction/master/Experimental/data/test.csv')\n",
    "\n",
    "def fill_ii(df):\n",
    "    df_filled_ii = pd.DataFrame(IterativeImputer().fit_transform(df.values))\n",
    "    df_filled_ii.columns = df.columns\n",
    "    df_filled_ii.index = df.index\n",
    "\n",
    "    return df_filled_ii\n",
    "\n",
    "def data_engineering(train, test):\n",
    "    train = train.drop(train.index[0])\n",
    "    \n",
    "    cc_data = pd.concat([train, test], sort=True)\n",
    "    cc_data = cc_data.drop(['Id', 'SalePrice','Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature'], axis=1)\n",
    "    \n",
    "    train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n",
    "    y = train['SalePrice']\n",
    "    \n",
    "    cc_data = pd.get_dummies(cc_data, prefix_sep='_')\n",
    "    \n",
    "    cc_data = fill_ii(cc_data)\n",
    "    \n",
    "    X_train = cc_data[:train.shape[0]]\n",
    "    X_test = cc_data[train.shape[0]:]\n",
    "    \n",
    "    return X_train,X_test,y\n",
    "\n",
    "X,X_test,y = data_engineering(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l3gXfOMgoODT"
   },
   "outputs": [],
   "source": [
    "class NestedCV():\n",
    "    '''A general class to handle nested cross-validation for any estimator that\n",
    "    implements the scikit-learn estimator interface.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : estimator\n",
    "        The estimator implements scikit-learn estimator interface.\n",
    "\n",
    "    params_grid : dict\n",
    "        The dict contains hyperparameters for model.\n",
    "\n",
    "    outer_kfolds : int\n",
    "        Number of outer K-partitions in KFold\n",
    "\n",
    "    inner_kfolds : int\n",
    "        Number of inner K-partitions in KFold\n",
    "\n",
    "    cv_options: dict, default = {}\n",
    "        Nested CV Options, check docs for details.\n",
    "\n",
    "        metric : callable from sklearn.metrics, default = mean_squared_error\n",
    "            A scoring metric used to score each model\n",
    "\n",
    "        metric_score_indicator_lower : boolean, default = True\n",
    "            Choose whether lowe score is better for the metric calculation or hight score is better, `True` means lower score is better.\n",
    "\n",
    "        sqrt_of_score : boolean, default = False\n",
    "            Whether or not if the square root should be taken of score\n",
    "\n",
    "        randomized_search : boolean, default = True\n",
    "            Whether to use gridsearch or randomizedsearch from sklearn\n",
    "\n",
    "        randomized_search_iter : int, default = 10\n",
    "            Number of iterations for randomized search\n",
    "\n",
    "        recursive_feature_elimination : boolean, default = False\n",
    "            Whether to do feature elimination\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model, params_grid, outer_kfolds, inner_kfolds, cv_options={}):\n",
    "        self.model = model\n",
    "        self.params_grid = params_grid\n",
    "        self.outer_kfolds = outer_kfolds\n",
    "        self.inner_kfolds = inner_kfolds\n",
    "        self.metric = cv_options.get('metric', mean_squared_error)\n",
    "        self.metric_score_indicator_lower = cv_options.get(\n",
    "            'metric_score_indicator_lower', True)\n",
    "        self.sqrt_of_score = cv_options.get('sqrt_of_score', False)\n",
    "        self.randomized_search = cv_options.get('randomized_search', True)\n",
    "        self.randomized_search_iter = cv_options.get(\n",
    "            'randomized_search_iter', 10)\n",
    "        self.recursive_feature_elimination = cv_options.get(\n",
    "            'recursive_feature_elimination', False)\n",
    "        self.outer_scores = []\n",
    "        self.best_params = {}\n",
    "        self.best_inner_score_list = []\n",
    "        self.variance = []\n",
    "\n",
    "    # to check if use sqrt_of_score and handle the different cases\n",
    "    def _transform_score_format(self, scoreValue):\n",
    "        if self.sqrt_of_score:\n",
    "            return np.sqrt(scoreValue)\n",
    "        return scoreValue\n",
    "\n",
    "    # to convert array of dict to dict with array values, so it can be used as params for parameter tuning\n",
    "    def _score_to_best_params(self, best_inner_params_list):\n",
    "        params_dict = {}\n",
    "        for best_inner_params in best_inner_params_list:\n",
    "            for key, value in best_inner_params.items():\n",
    "                if key in params_dict:\n",
    "                    if value not in params_dict[key]:\n",
    "                        params_dict[key].append(value)\n",
    "                else:\n",
    "                    params_dict[key] = [value]\n",
    "        return params_dict\n",
    "\n",
    "    # a method to handle  recursive feature elimination\n",
    "    def _fit_recursive_feature_elimination(self, best_inner_params, X_train_outer, y_train_outer, X_test_outer):\n",
    "        print('\\nRunning recursive feature elimination for outer loop... (SLOW)')\n",
    "        # K-fold (inner_kfolds) recursive feature elimination\n",
    "        rfe = RFECV(estimator=self.model, min_features_to_select=20,\n",
    "                    scoring='neg_mean_squared_error', cv=self.inner_kfolds, n_jobs=-1)\n",
    "        rfe.fit(X_train_outer, y_train_outer)\n",
    "\n",
    "        # Assign selected features to data\n",
    "        print('Best number of features was: {0}'.format(rfe.n_features_))\n",
    "        X_train_outer_rfe = rfe.transform(X_train_outer)\n",
    "        X_test_outer_rfe = rfe.transform(X_test_outer)\n",
    "\n",
    "        # Train model with best inner parameters on the outer split\n",
    "        self.model.set_params(**best_inner_params)\n",
    "        self.model.fit(X_train_outer_rfe, y_train_outer)\n",
    "        return self.model.predict(X_test_outer_rfe)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''A method to fit nested cross-validation \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas dataframe (rows, columns)\n",
    "            Training dataframe, where rows is total number of observations and columns\n",
    "            is total number of features\n",
    "    \n",
    "        y : pandas dataframe\n",
    "            Output dataframe, also called output variable. y is what you want to predict.\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        It will not return directly the values, but it's accessable from the class object it self.\n",
    "        You should be able to access:\n",
    "        \n",
    "        variance\n",
    "            Model variance by numpy.var()\n",
    "            \n",
    "        outer_scores \n",
    "            Outer score List.\n",
    "            \n",
    "        best_inner_score_list \n",
    "            Best inner scores for each outer loop\n",
    "            \n",
    "        best_params \n",
    "            All best params from each inner loop cumulated in a dict\n",
    "            \n",
    "        best_inner_params_list \n",
    "            Best inner params for each outer loop as an array of dictionaries\n",
    "        '''\n",
    "    \n",
    "        print('\\n{0} <-- Running this model now'.format(type(self.model).__name__))\n",
    "        outer_cv = KFold(n_splits=self.outer_kfolds, shuffle=True)\n",
    "        inner_cv = KFold(n_splits=self.inner_kfolds, shuffle=True)\n",
    "        model = self.model\n",
    "    \n",
    "        outer_scores = []\n",
    "        variance = []\n",
    "        best_inner_params_list = []  # Change both to by one thing out of key-value pair\n",
    "        best_inner_score_list = []\n",
    "    \n",
    "        # Split X and y into K-partitions to Outer CV\n",
    "        for (i, (train_index, test_index)) in enumerate(outer_cv.split(X, y)):\n",
    "            print('\\n{0}/{1} <-- Current outer fold'.format(i+1, self.outer_kfolds))\n",
    "            X_train_outer, X_test_outer = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train_outer, y_test_outer = y.iloc[train_index], y.iloc[test_index]\n",
    "            best_inner_params = {}\n",
    "            best_inner_score = None\n",
    "    \n",
    "            # Split X_train_outer and y_train_outer into K-partitions to be inner CV\n",
    "            for (j, (train_index_inner, test_index_inner)) in enumerate(inner_cv.split(X_train_outer, y_train_outer)):\n",
    "                print('\\n\\t{0}/{1} <-- Current inner fold'.format(j+1, self.inner_kfolds))\n",
    "                X_train_inner, X_test_inner = X_train_outer.iloc[\n",
    "                    train_index_inner], X_train_outer.iloc[test_index_inner]\n",
    "                y_train_inner, y_test_inner = y_train_outer.iloc[\n",
    "                    train_index_inner], y_train_outer.iloc[test_index_inner]\n",
    "    \n",
    "                # Run either RandomizedSearch or GridSearch for input parameters\n",
    "                for param_dict in ParameterSampler(param_distributions=self.params_grid, \n",
    "                                                   n_iter=self.randomized_search_iter) if (self.randomized_search) else (\n",
    "                                                           ParameterGrid(param_grid=self.params_grid)):\n",
    "                    # Set parameters, train model on inner split, predict results.\n",
    "                    if(type(self.model).__name__ == 'KerasRegressor'):\n",
    "                        with tf.device('/gpu:0'):\n",
    "                          model.set_params(**param_dict)\n",
    "                          model.fit(X_train_inner, y_train_inner)\n",
    "                    else:\n",
    "                      model.set_params(**param_dict)\n",
    "                      model.fit(X_train_inner, y_train_inner)\n",
    "                    \n",
    "                    \n",
    "                    inner_pred = model.predict(X_test_inner)\n",
    "                    inner_grid_score = self.metric(y_test_inner, inner_pred)\n",
    "                    current_inner_score_value = best_inner_score\n",
    "                    # Find best score and corresponding best grid\n",
    "                    if(best_inner_score is not None):\n",
    "                        if(self.metric_score_indicator_lower and best_inner_score > inner_grid_score):\n",
    "                            best_inner_score = self._transform_score_format(inner_grid_score)\n",
    "                            \n",
    "                        elif (not self.metric_score_indicator_lower and best_inner_score < inner_grid_score):\n",
    "                            best_inner_score = self._transform_score_format(inner_grid_score)\n",
    "                    else:\n",
    "                        best_inner_score = self._transform_score_format(inner_grid_score)\n",
    "                        current_inner_score_value = best_inner_score+1  # first time random thing\n",
    "                        \n",
    "                    # Update best_inner_grid once rather than calling it under each if statement\n",
    "                    if(current_inner_score_value is not None and current_inner_score_value != best_inner_score):\n",
    "                        best_inner_params = param_dict\n",
    "    \n",
    "            best_inner_params_list.append(best_inner_params)\n",
    "            best_inner_score_list.append(best_inner_score)\n",
    "    \n",
    "            if self.recursive_feature_elimination:\n",
    "                pred = self._fit_recursive_feature_elimination(\n",
    "                    best_inner_params, X_train_outer, y_train_outer, X_test_outer)\n",
    "            else:\n",
    "                # Train model with best inner parameters on the outer split\n",
    "                model.set_params(**best_inner_params)\n",
    "                model.fit(X_train_outer, y_train_outer)\n",
    "                pred = model.predict(X_test_outer)\n",
    "    \n",
    "            outer_scores.append(self._transform_score_format(\n",
    "                self.metric(y_test_outer, pred)))\n",
    "    \n",
    "            # Append variance\n",
    "            variance.append(np.var(pred, ddof=1))\n",
    "    \n",
    "            print('\\nResults for outer fold:\\nBest inner parameters was: {0}'.format(\n",
    "                best_inner_params_list[i]))\n",
    "            print('Outer score: {0}'.format(outer_scores[i]))\n",
    "            print('Inner score: {0}'.format(best_inner_score_list[i]))\n",
    "    \n",
    "        self.variance = variance\n",
    "        self.outer_scores = outer_scores\n",
    "        self.best_inner_score_list = best_inner_score_list\n",
    "        self.best_params = self._score_to_best_params(best_inner_params_list)\n",
    "        self.best_inner_params_list = best_inner_params_list\n",
    "\n",
    "    # Method to show score vs variance chart. You can run it only after fitting the model.\n",
    "    def score_vs_variance_plot(self):\n",
    "        # Plot score vs variance\n",
    "        plt.figure()\n",
    "        plt.subplot(211)\n",
    "\n",
    "        variance_plot, = plt.plot(self.variance, color='b')\n",
    "        score_plot, = plt.plot(self.outer_scores, color='r')\n",
    "\n",
    "        plt.legend([variance_plot, score_plot],\n",
    "                   [\"Variance\", \"Score\"],\n",
    "                   bbox_to_anchor=(0, .4, .5, 0))\n",
    "\n",
    "        plt.title(\"{0}: Score VS Variance\".format(type(self.model).__name__),\n",
    "                  x=.5, y=1.1, fontsize=\"15\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NestedCV parameters\n",
    "NUM_TRIALS = 50\n",
    "outerFolds = 5\n",
    "innerFolds = 5\n",
    "\n",
    "models_to_run = [RandomForestRegressor()]\n",
    "models_param_grid = [\n",
    "                    { # 2nd param grid, corresponding to RandomForestRegressor\n",
    "                            'max_depth': [3, None],\n",
    "                            'n_estimators': [100,200,300,400,500,600,700,800,900,1000],\n",
    "                            'max_features' : [50,100,150,200]\n",
    "                    }\n",
    "                    ]\n",
    "RF_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "0pKVdTkjogUk",
    "outputId": "cd9796fc-a54f-4f49-e747-fe3f1f48945f",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 0 / 1\n",
      "\n",
      "RandomForestRegressor <-- Running this model now\n",
      "\n",
      "1/2 <-- Current outer fold\n",
      "\n",
      "\t1/2 <-- Current inner fold\n",
      "\n",
      "\t2/2 <-- Current inner fold\n",
      "\n",
      "Results for outer fold:\n",
      "Best inner parameters was: {'n_estimators': 100, 'max_features': 50, 'max_depth': 3}\n",
      "Outer score: 0.1966926046351545\n",
      "Inner score: 0.20663180445853452\n",
      "\n",
      "2/2 <-- Current outer fold\n",
      "\n",
      "\t1/2 <-- Current inner fold\n",
      "\n",
      "\t2/2 <-- Current inner fold\n",
      "\n",
      "Results for outer fold:\n",
      "Best inner parameters was: {'n_estimators': 800, 'max_features': 150, 'max_depth': None}\n",
      "Outer score: 0.14317151790418264\n",
      "Inner score: 0.14825713448623434\n",
      "\n",
      "Cumulated best parameter grids was:\n",
      "{'n_estimators': [100, 800], 'max_features': [50, 150], 'max_depth': [3, None]}\n",
      "\n",
      "Fitting with optimal parameters:\n",
      "{'max_depth': None, 'max_features': 50, 'n_estimators': 800}\n",
      "\n",
      "Final score for RandomForestRegressor was 0.13819998404466372\n"
     ]
    }
   ],
   "source": [
    "for trial in range(NUM_TRIALS):\n",
    "    print('Running {0} / {1}'.format(trial,NUM_TRIALS))\n",
    "    for i,model in enumerate(models_to_run):\n",
    "        nested_CV_search = NestedCV(model=model, params_grid=models_param_grid[i], outer_kfolds=outerFolds, inner_kfolds=innerFolds, \n",
    "                          cv_options={'sqrt_of_score':True, 'randomized_search_iter':30})\n",
    "        nested_CV_search.fit(X=X,y=y)\n",
    "        model_param_grid = nested_CV_search.best_params\n",
    "        print('\\nCumulated best parameter grids was:\\n{0}'.format(model_param_grid))\n",
    "        \n",
    "        gscv = GridSearchCV(estimator=model,param_grid=model_param_grid,scoring='neg_mean_squared_error',cv=5, n_jobs=-1)\n",
    "        gscv.fit(X,y)\n",
    "        \n",
    "        print('\\nFitting with optimal parameters:\\n{0}'.format(gscv.best_params_))\n",
    "        gscv.predict(X_test)\n",
    "        score = np.sqrt(-gscv.best_score_)\n",
    "        \n",
    "        if(type(model).__name__ == 'KerasRegressor'):\n",
    "            NN_scores.append(score)\n",
    "        elif(type(model).__name__ == 'RandomForestRegressor'):\n",
    "            RF_scores.append(score)\n",
    "        elif(type(model).__name__ == 'XGBRegressor'):\n",
    "            XGB_scores.append(score)\n",
    "        \n",
    "        print('\\nFinal score for {0} was {1}'.format(type(model).__name__,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.1, 'Test scores as RMSLE with hyperparameter optimization')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbgAAAEgCAYAAADG/2adAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xu8V3Wd7/HXm4uCecELWoFHOKOmCAK5I9HAu+JMoJWkZilWOkaOR2dyhqZOU9h01LSLytG00i4WyphlRydzSC27kBvECyqKiLKBFDWYTAGRz/nj+/3h8sdv7/0DFmxZvJ+Px+/BXmt9v9/1WWt9f+uz1netvVFEYGZmVjXdujoAMzOzTcEJzszMKskJzszMKskJzszMKskJzszMKskJzszMKqnDBCcpmvgcXkYgkgZJ+qKk7ctozxJJ+9Udr79IekDSGQ3K/iGXubLBsr0LbRxcmL+DpP8j6QlJKyQ9J+luSacXyozJ9fbuIM4/tdO/Xi5jPxTWc7GktsJ0w34n6Zy8/h7r2X6vXO+TZcVsG0/SO/Nx7t/VsTSrvZib+T6txzo2qJ930uZ2Oe7BdfNr56Kjy1pXZzq7gxtZ+ByZ5325bv6skmIZBPwb4AS3aZxHOl4fAh4HbpB0UoNyLwPjJXWvm39qXlbv58AZwDeAMcD/Aubmn9fXDby5b40EjtiAdjoyBRhbmHa/2zq8k3Sct5gER/sx/5703VhYwjp+AoyMiNUltFWzHSnuwXXzF5Di/mOJ6+pQh1k7Iv5Q+7lwhftUcf7WRFLviHi1q+PYQI/Vjpuk6cAI4HTgP+rK/RdwLCmx/Fdh/snAbcBHajMkDQEOA8ZFxM8LZadK0gbEuGhT962IWEg5J4YtWr6A6RYRr23CdQjYJiJWbqp1dJWuPBdExHKglO9JRDwPPF9GW02sawUlxd2s0p7BSRooaZqkZZL+Kul2SX9TWC5JX5A0Pw9l/UnSHZJ2lTQGmJaLLsm3sY93sK6hku6S9GdJL0uaI+msujLjJbVKelXSC5L+n6R+heXHSrq/EMsVknoXlteGAY7Mcf4VuCwv6y7pf+dtWSnpcUkfqVv/4ZJ+l4cEl0uaJemEDrZJki6X9EjefwslfU9S37pyH1IaYnxF0kuSfi/pkA4PTp2IeB14BNizweK/ArcDpxTWOQTYH7i5rmyf/O+fGqxjk/+JHEkTcx/olqcl6UVJiwpleub9+bE8vXaIssl+t4+kX+X9/aik9zcZXg9Jl+Z4npP0TUk983r3kPSapJPrtqe7pEWSvlKMNfel2bmvzlRhiLhQ91OSHsv98WlJ59ctnyrpPkkflvQYsBIYpjeGqIbn/roi9+e/q6t/Yt4PS3N//p2kI+rK1OI9QtKsvI5xknaUdLXSMPYr+XvzTRWGhfXG0O7EvOwlSc9LOi8vP0vSgny8vyVpm7p1D1Q75x9J+wH356K/z+tZUajbV9J38vpelfQbSQc1iO1cSVdJeqHQ3jokbS/p/xbam9FgX/1B0g9zm8/m/fIzSW/vLGbVDVFuzL5T3RBl7ieNHhX8Ii/v8FhK6gUszc3/uFD/7WowRCmph6R/VzrfrZT0sKTxdfuq1nf/Vulc/7KkeyW9q71jsFZENPUhDeEEMKHBst2BxfmAnASMA2YAT5Gu4ADOBpYDfw+MJg2VXU26/d4J+Gxu/2+Bg4Gh7cTRDWgDfgocDxwFnAt8plDmk7mt7wPvB04ArgQOzMuHA6/lNv4W+DTwF+CnhTbG5DaeJd1uHwkcnJd9B/hv4J+Ao4GvAWuAY/LyXXN7387LjwMubLTvCuvrDlxPSiyHAR/O+/MBQLnMoBz3V0h3WH+XY/u7DtrdL2/H0XXzHwB+UjfvD8APgQ8ALxWO3VeAe4CW3NbBhe18NR/ro4Ft24mhti/37iDOPwH/ThpVKH66dVBncG53aJ4eAqwCXgf+Js8bmcsMyNMXA23553b7HXBOnv8gMJF0V3tn3t49OoipV6HfXJfrfTb3j/MK5W4FflFX9/hcd99CrP8NPA18gjS0+ltgGbBrod7/JiWTL+Xj8Pm8Hz5ZKDOVdKX+OOku/Fjg7YXtnAdckGO4Ldffv1D/AtL37Nj8uRJYDbQUylxM6vdPkb6DRwJ7A/2Aq0jf+cNIQ9pPAj9rsN8W5rLHkM4PAVwK3EXq7+eRvgPnN3v+yW1PyG19Ih/nEblub9LF3pPAR/P235H38W51sS0hfT/GAGM66AO3kM51E0n96ud5f46o+64tIj3i+QDwsdz+bwrrbC/mN32fNnLf1Y5/jzy9d15X7XMSqW9dkZd3eCwBkc53QeqHtXZ60uBcBFye25+U612fy3ygru/+Ke+r8cCJwHxgVqd5q6QE99UcwE6FeX1Jz2w+kae/DdzYQfsn5fbf3kkc/XO5fdpZ3pP0Rf5RB238FJhD4eRJGq4LYHhdJ/o/dXUPyPNPrpt/c6Fzvo90Qmt4wm9yf3cH/iavq9axP0oaxlufdmqd6lhSwtgF+BfSifrgurK1BLct6Qs6Ns9/Kn8R3pTg8rIzSHd9kTvqPcDHyUm50ReynTj/lMvUf37RQR0BLwLn5umJpATwQK2fAv8MLCzUWZvgOup3vPHF/0hh3jva+w4UytRONr+sm/8L4J7C9PtJibhfXR+6ry7WAD5YmNeHlES+mKd3ycfyX+rWdynwbGF6au6T+7eznf9Y1/eeBm5oZxu75b50L/B/G8R7XCd9sgfpwnQN+WKhsN/+s67ci6Q7gu0K828D7i1MN3P+Wafv5vmfzvtvQGHetqRkcVFdbL9v4vs2jLrzQ96f9Qn9D6TvyzsK847KdQ/vJOb2EtyG7Ls3Jbi69WxLel42C+i9Hsdyt9zmKe2ci47O03sAKxr03V8BD9b13VXAXoV5p1C4cG3vU9YQ5dGkL/Bf8y1nD+DPpKvfllxmNnCi0jBli/Kw0gZ4jtSZr1Mahuxbt3wwqXNf30EbI4BbImJNYd7NpB32vrqyt9dNH03qmD+vbWve3ulAbVjjCdKBmypprKSdmtkwSePy0MVy0tXxvLxo3/zvQ8A7JH1b0tGStmum3exO0tXbi6QT0f+Kdp53RXpm8lPgFEkjgP/Bus/qamW/BwwAziIN9+1PusP97nrEVvNd4D11n39or3Cknv5bYFSeNRr4df4U5/1mA2Kp+WVhfUtI/bqZFxV+WTf9aF29/yT149MBJO1MuvOo77evk05KtRiWkU4AI/KsUaQT3LQG/XFPSXsU2pofEY+1E++thXXU1llbB5L2knSjpMWkvvkaad/uW9fOa6Q7hjeR9HFJDyoN9b9Ger4rYJ+6otMLcawGngFmRMQrhTLzSHcSNc2cf9pzNOlur61Q93VSn6mvW38uaGRErv+Twna8Tvr+1J9b/pD7VK3cdNId+wg2zIbsu45cTbrI/mAUnjeux7HszFBSEp1WN/8m4EBJOxbmPRERzxSmH83/dvhdLCvB7Ua6kn+t7nMIbzznuZo0hHIaaSjhT5L+bX0TXaSH4seQhhC+l9u5R+k5EaRhM0i3++uQJNKVw3N17a4gda5d6qo8Vze9G+mg1A5u7XMN0FvSbpEe3B5Huuu9BVgq6TZJe7W3XZIOJZ1kniLdqY0knUAgncCIiIeAD5KSyJ3AC5K+L6k+5kY+TUoYY0n7/wpJ+3dQfirphPtxYHpEvNBewYhYGhHfjoiPko73jcCE/BxhfSyJiNa6z5Od1Ckms1GkE9NvgFG5bx3KxiW4ZXXTq8jHY2Pq5ZPe90jDUJCGDVez7nPOP8e6b7g9T7qbhNQfIfWbYn/8RZ5ffM5a35fr22y4jnzSv510AfevwOGkvvQr1t0XS+suHJF0Kumi517SHfN7eeMZb339Rvuts2PQzPmnPbuRhtrq657aoG5H+6/mHaRjVv/yznPAznXzGr3cUTy262tD9l1Dks4l7dNTI2JBYf76HMvO1Lazfr/Wpov7q9F2dLrOsn734SXSLfclDZYth7Vf6EuBS/OJ/nRSwnuG9Hp40yLiEdLd4DakznkpaZx7AOkOBdLOe6RB3ZD0HGncfq38cHTHvC1vqlI3/RLp7mwUjS3L6/kNcIykt5ES8tdJJ7TD26n3IdKQ0mmFmNZ5iBoRPwV+KqkPKVl9gzQ8MKGddmueiIjW3O4M0pDJV0jj/43cRbpTPYv0DKApEbFK0jdJFzLvIj3z2ZR+A3xVUu2Z0m9JnX4f0tV5HzYuwW1K3wEmKb0kNAH4j4j4S12ZnSX1qEtyu/PGBVytvx5LumupV7xjq+/LRbuThiUbrWMQaWj+iIi4p1YgjyC8XtdOo3WMJw2LnVeoW3+y3xidnn86qftb4PwGy+rfkuxo/9UsIR2znnVJbg/WPT67s67ifu8SkkaR3iv4fETUj0SUeSxr21nf92qjDo3683opK8FNJz2cfSgiVnVWON9qXqT0y7CD8uymMnJdO6uAuyRdAXw3J5OHSVdBZ9BgqCSbAXxI0hfzMBekAyfgvk5WW7tq7Z2TWGcx/pWUkIYDn+qgaG/e2Ac1pzUqmNtdBvwgv5E0qL1y7dRdKuly4EuS9ouIdZJQRKxWeptvFIXhq6I8hLAy1n0NvDZU0cwV78aaSbqb/hxp3H45sFzSE3nen0nPW9uz3v2uLBHxlKR7SUPGLcBnGhTrTrqT/glAHu4+kvRwHlJ/XUV6hthef2/GB0gntdqvEIwjXaVD6puQLnjIZfYh3cU189p372LdrN2+vQGaOf+0d5ynk17SmR8R9Re3G+KPpGP2AfLdeN6fH2Ldc8vBkt5RG6aUdBTpIrv2e2KbvW8q/VL5NNINw8UNijRzLJuN+8Hc1njSTUrNh0nH8r+bibkjZSW4S0m3qdMlTSFl5reT7lb+KyJukXQ96a2hP5KGAo8lDQHcnduonWQnSroFeDki1jkx5WdCXyJ1nqdJQwz/RBpr/msuM4mU8FaTDpZIV/PfzcN8k0nDdLdIug4YSDqYP4uIBzra0Ih4MG/LTyRdQnoAux3p2d9eEfEpSR/M++NnpDc+9yQN9f2qg6bvAs6R9FXS8NJoCq/q5+06Dzgwl11Cemh7Imn4d31dSTqh/hPpLq3Rtn6NfNJrx4GkV4GvB35H6qzvJiWWP7LuL3SOkVT/KwUPR8Tc/HM/NXgFHmhtMExXi3G1pD+QHnR/s7DoN6Q7z58XLmIaaarfbULfAX5AGmL8dYPlfwG+lq+Snye9bbaG9CZb7WLl34GrlV4bv4/0vX4XcEhEfLjJOCZKWkP6Jf1PkZ5t1E46D5MuVr4p6d9IQ0eTSX27GXeR7rL/mfQC0DjWfR61MTo9/5DOFauAMyWtJF2YzSK9/HYWcI+kr/HGOWUk8HRETFmfQCJitqSfANfmRwfPkPbnANZNBC8At0uaTHqc8VXgd4W75PZi3pR+RHrz9BrgvXrj11mX5QvhTo9lRPy3pCWkZ/hPks4Ls+tXFBHP5eM1Oa/nQdLv2x5JehSz8Tp6A6XuzZZ236LMy/ckvZb/PGkI72nSkNy78vKzSL+B/2fSFfds4PS6Nj5Ler36deDxdtbTj3QQns7rWUI6QfSrK3cy6QCsJHWk24B3FpYfB7Tm5c8BV/Dmt43affOP9OzyM6Thn5WkN5XuJo1XQ0p2PyGdAFaS3siaQuEtr3a27fOk153/Skpyg3IMn8zLR5NeTliSt30+6dX6nh202fDXBPKyr+R23h5vvNn1ww7aavRrAl8mXSy8lON+LMfUp8G+bPSZlMu09xZlkF/X7iCuf2Pdtw3PyPP+ua7sm96ibK/f0c7bZTnOL3cQS+2Ntk92tt48f0dSwvp8g2UX5z50JCnJrCT16UMalD0zL1uRj8XvgX8oLJ9K4Q3Nwvzadh6Uj/8KUpIbV1duJOlu+dW8/CP1bXawjT1JFx/Pky5ubyKdFItv1LW339bpk+0cww7PP4V9NI/0jG1FYf4upO/nIlJCWUi6MB7RUWwd9IHtSRedS3MsM4AjG20X6dX9trxff07hHNVezLT/FuV67zvW/TWBDt9mbuZY5nJ/R3pEtCIvezuNf02gB+l80Zb3/cPAh+tiXqfvNmqr0af2+1Vm1gXy3f400uvOC+uWXQx8NCI22Z+XknQO6WTcM8r9c03WgTzqMC/Si1m2iZT2BzbNrHlKf1VnX9Id8K31yc3MNp7/uxyzrvEPpOcZy2j8Bp+ZbSQPUZqZWSX5Ds7MzCrJCc7MzCrJCc7MzCrJCc7MzCrJCc7MzCrJCc7MzCrJCc7MzCrJCc7MzCrJCc7MzCrJCc7MzCrJCc7MzCrJCc7MzCrJCc7MzCrJCc7MzCrJCc7MzCrJCc7MzCrJCc7MzCrJCc7MzCrJCc7MzCrJCc7MzCrJCc7MzCrJCc7MzCrJCc7MzCqpR1cHsCnstttuMWDAgK4Ow8xsizJz5swXIqJvV8dRlkomuAEDBtDa2trVYZiZbVEkPdPVMZTJQ5RmZlZJTnBmZlZJTnBmZlZJTnBmZlZJTnBmZlZJTnBmZlZJTnBmZlZJTnBmZlZJTnBmZlZJTnBmZlZJTnBmZlZJTnBmZlZJTnBmZlZJTnBmZlZJTnBmZlZJTnBmZlZJTnBmZlZJTnBmZlZJTnBmZlZJTnBmZlZJTnBmZlZJpSY4SWMkzZU0T9KkBstHS5olabWkkxos31HSIklXNVh2m6RHyozXzMyqq7QEJ6k7MAU4HhgEnCppUF2xZ4EJwI/aaeYi4N4GbX8QeLmsWM3MrPrKvIMbAcyLiPkRsQqYCpxQLBARCyLiIWBNfWVJBwF7AL+sm7898I/Al0uM1czMKq7MBNcPWFiYbsvzOiWpG3A5cGGDxRflZa900sbZkloltS5durS5iM3MrLLKTHBqMC+arDsRuCMiigkSScOAvSPi1s4aiIhrI6IlIlr69u3b5GrNzKyqepTYVhuwZ2G6P7C4ybojgVGSJgLbA9tIehl4BjhI0oIc6+6S7omIw0uL2szMKqnMBHc/sI+kgcAi4BTgI81UjIjTaj9LmgC0RETtLcyr8/wBwP9zcjMzs2aUNkQZEauBc4E7gceAmyNijqTJksYBSHqPpDZgPPAtSXPKWr+ZmVmRIpp9TLblaGlpidbW1q4Ow8xsiyJpZkS0dHUcZfFfMjEzs0pygjMzs0pygjMzs0pygjMzs0pygjMzs0pygjMzs0pygjMzs0pygjMzs0pygjMzs0pygjMzs0pygjMzs0pygjMzs0pygjMzs0pygjMzs0pygjMzs0pygjMzs0pygjMzs0pygjMzs0pygjMzs0oqNcFJGiNprqR5kiY1WD5a0ixJqyWd1GD5jpIWSboqT28n6XZJj0uaI+niMuM1M7PqKi3BSeoOTAGOBwYBp0oaVFfsWWAC8KN2mrkIuLdu3mURsR8wHDhU0vFlxWxmZtVV5h3cCGBeRMyPiFXAVOCEYoGIWBARDwFr6itLOgjYA/hlofwrEXF3/nkVMAvoX2LMZmZWUWUmuH7AwsJ0W57XKUndgMuBCzso0wcYC0zfiBjNzGwrUWaCU4N50WTdicAdEbGw0UJJPYAfA1dExPx2ypwtqVVS69KlS5tcrZmZVVWPEttqA/YsTPcHFjdZdyQwStJEYHtgG0kvR0TtRZVrgScj4hvtNRAR1+ZytLS0NJtYzcysospMcPcD+0gaCCwCTgE+0kzFiDit9rOkCUBLLblJ+jKwE/DJEmM1M7OKK22IMiJWA+cCdwKPATdHxBxJkyWNA5D0HkltwHjgW5LmdNSmpP7A50hvZc6SNFuSE52ZmXVKEdUbzWtpaYnW1tauDsPMbIsiaWZEtHR1HGXxXzIxM7NKcoIzM7NKcoIzM7NKcoIzM7NKcoIzM7NKcoIzM7NKcoIzM7NKcoIzM7NKcoIzM7NKcoIzM7NKcoIzM7NKcoIzM7NKcoIzM7NKcoIzM7NKcoIzM7NKcoIzM7NKcoIzM7NKcoIzM7NKcoIzM7NKcoIzM7NKKjXBSRojaa6keZImNVg+WtIsSaslndRg+Y6SFkm6qjDvIEkP5zavkKQyYzYzs2oqLcFJ6g5MAY4HBgGnShpUV+xZYALwo3aauQi4t27e1cDZwD75M6akkM3MrMLKvIMbAcyLiPkRsQqYCpxQLBARCyLiIWBNfWVJBwF7AL8szHsHsGNE/D4iAvg+cGKJMZuZWUWVmeD6AQsL0215XqckdQMuBy5s0GZbM21KOltSq6TWpUuXNh20mZlVU5kJrtGzsWiy7kTgjohYWDe/6TYj4tqIaImIlr59+za5WjMzq6oeJbbVBuxZmO4PLG6y7khglKSJwPbANpJeBr6Z29mQNs3MbCtWZoK7H9hH0kBgEXAK8JFmKkbEabWfJU0AWiJiUp7+i6SDgRnA6cCVJcZsZmYVVdoQZUSsBs4F7gQeA26OiDmSJksaByDpPZLagPHAtyTNaaLpTwHfBuYBTwH/WVbMZmZWXUovJ1ZLS0tLtLa2dnUYZmZbFEkzI6Klq+Moi/+SiZmZVZITnJmZVZITnJmZVZITnJmZVZITnJmZVZITnJmZVZITnJmZVZITnJmZVZITnJmZVZITnJmZVZITnJmZVZITnJmZVZITnJmZVZITnJmZVZITnJmZVZITnJmZVZITnJmZVZITnJmZVZITnJmZVZITnJmZVVKpCU7SGElzJc2TNKnB8tGSZklaLemkwvy9JM2UNFvSHEnnFJadKulhSQ9J+oWk3cqM2czMqqm0BCepOzAFOB4YBJwqaVBdsWeBCcCP6uYvAQ6JiGHAe4FJkt4pqQfwTeCIiDgQeAg4t6yYzcysusq8gxsBzIuI+RGxCpgKnFAsEBELIuIhYE3d/FURsTJPbluIS/nzNkkCdgQWlxizmZlVVJkJrh+wsDDdluc1RdKekh7KbVwSEYsj4jXgU8DDpMQ2CPhOO/XPltQqqXXp0qUbug1mZlYRZSY4NZgXzVaOiIV5GHJv4AxJe0jqSUpww4F3koYoP9tO/WsjoiUiWvr27bv+0ZuZWaWUmeDagD0L0/3ZgOHEiFgMzAFGAcPyvKciIoCbgUM2PlQzM6u6MhPc/cA+kgZK2gY4BbitmYqS+kvqnX/eGTgUmAssAgZJqt2SHQM8VmLMZmZWUT3KaigiVks6F7gT6A58NyLmSJoMtEbEbZLeA9wK7AyMlfSliDgA2B+4XFKQhjovi4iHASR9Cfi1pNeAZ0hvYZqZmXVIaeSvWlpaWqK1tbWrwzAz26JImhkRLV0dR1n8l0zMzKySnODMzKySnODMzKySnODMzKySnODMzKySnODMzKySnODMzKySnODMzKySnODMzKySnODMzKySnODMzKySnODMzKySnODMzKySnODMzKySnODMzKySnODMzKySnODMzKySnODMzKySenR1ANax1157jba2NlasWNHVodh66NWrF/3796dnz55dHYrZVqvUBCdpDPBNoDvw7Yi4uG75aOAbwIHAKRHxH3n+XsBPcr2ewJURcU1etg1wFXA4sAb4XETcUmbcb2VtbW3ssMMODBgwAEldHY41ISJ48cUXaWtrY+DAgV0djtlWq7QEJ6k7MAU4BmgD7pd0W0Q8Wij2LDAB+Exd9SXAIRGxUtL2wCO57mLgc8DzEbGvpG7ALmXFvCVYsWKFk9sWRhK77rorS5cu7epQzLZqZd7BjQDmRcR8AElTgROAtQkuIhbkZWuKFSNiVWFyW978bPDjwH653BrghRJj3iI4uW15fMzMul6ZL5n0AxYWptvyvKZI2lPSQ7mNSyJisaQ+efFFkmZJmiZpj/JCtmZ0796dYcOGMXjwYMaOHcuyZctKaXfBggUMHjy4lLaKvvjFL9KvXz+GDRvGsGHDmDRpUunrqJk9ezZ33HHHJmvfzDZcmQmu0SVrNFs5IhZGxIHA3sAZOZH1APoDv42IdwO/By5ruHLpbEmtklo9NFSu3r17M3v2bB555BF22WUXpkyZ0tUhdeqCCy5g9uzZzJ49m4svvrjzCtnrr7++XutxgjN76yozwbUBexam+wOL17eR/NxtDjAKeBF4Bbg1L54GvLudetdGREtEtPTt23d9V2tNGjlyJIsWLQLg5Zdf5qijjuLd7343Q4YM4Wc/+xmQ7sz2339/zjrrLA444ACOPfZYXn31VQBmzpzJ0KFDGTly5JsS5YoVKzjzzDMZMmQIw4cP5+677wbghhtu4MQTT2Ts2LEMHDiQq666iq997WsMHz6cgw8+mJdeeqnp2KdPn87w4cMZMmQIH//4x1m5ciUAAwYMYPLkybzvfe9j2rRpPPXUU4wZM4aDDjqIUaNG8fjjjwMwbdo0Bg8ezNChQxk9ejSrVq3iC1/4AjfddBPDhg3jpptu2vgdbGalKfMZ3P3APpIGAouAU4CPNFNRUn/gxYh4VdLOwKHA1yIiJP2c9Ablr4CjKDzT29qcfz7Mnl1um8OGwTe+0VzZ119/nenTp/OJT3wCSK/C33rrrey444688MILHHzwwYwbNw6AJ598kh//+Mdcd911fPjDH+aWW27hox/9KGeeeSZXXnklhx12GBdeeOHatmvJ7uGHH+bxxx/n2GOP5YknngDgkUce4YEHHmDFihXsvffeXHLJJTzwwANccMEFfP/73+f8889fJ9avf/3r/PCHPwTgkksu4bDDDmPChAlMnz6dfffdl9NPP52rr756bd1evXpx3333AXDUUUdxzTXXsM8++zBjxgwmTpzIr371KyZPnsydd95Jv379WLZsGdtssw2TJ0+mtbWVq666agP2vpltSqXdwUXEauBc4E7gMeDmiJgjabKkcQCS3iOpDRgPfEvSnFx9f2CGpAeBe4HLIuLhvOxfgC/m53MfA/6prJitOa+++irDhg1j11135aWXXuKYY44B0uvw//qv/8qBBx7I0UcfzaJFi3juuecAGDhwIMOGDQPgoIMOYsGCBSxfvpxly5Zx2GGHAfCxj31s7Truu+++tdP77bcfe+2119oEd8QRR7DDDjvQt29fdtppJ8aOHQvAkCFDWLBgQcOYi0OUxx13HHPnzmXgwIHsu+++AJxxxhn8+te/Xlv+5JNPBtJd6e9+9zvGjx/PsGHD+Pu//3uWLFkCwKGHHsqECRO47rqP/MljAAAK1klEQVTr1nso08w2v1J/Dy4i7gDuqJv3hcLP95OGLuvr3UX63bhGbT4DjC4zzi1Vs3daZas9g1u+fDnvf//7mTJlCueddx433ngjS5cuZebMmfTs2ZMBAwas/YX0bbfddm397t278+qrrxIR7b5dGNH+49piW926dVs73a1bN1avXt3UNnTUPsDb3vY2ANasWUOfPn2Y3eBW+ZprrmHGjBncfvvtDBs2rGEZM3vr8J/qsqbttNNOXHHFFVx22WW89tprLF++nN13352ePXty991388wzz3RYv0+fPuy0005rhwJvvPHGtctGjx69dvqJJ57g2Wef5V3veldpse+3334sWLCAefPmAfCDH/xg7Z1k0Y477sjAgQOZNm0akBLjgw8+CMBTTz3Fe9/7XiZPnsxuu+3GwoUL2WGHHfjLX/5SWpxmVh4nOFsvw4cPZ+jQoUydOpXTTjuN1tZWWlpauPHGG9lvv/06rX/99dfz6U9/mpEjR9K7d++18ydOnMjrr7/OkCFDOPnkk7nhhhvedOe2sXr16sX111/P+PHjGTJkCN26deOcc85pWPbGG2/kO9/5DkOHDuWAAw5Y+/LMhRdeyJAhQxg8eDCjR49m6NChHHHEETz66KN+ycTsLUidDd1siVpaWqK1tbWrwyjFY489xv7779/VYdgG8LGzLY2kmRHR0tVxlMV3cGZmVklOcGZmVklOcGZmVklOcFuAKj4nrTofM7Ou5wT3FterVy9efPFFnzC3ILX/D65Xr15dHYrZVs3/o/dbXP/+/Wlra/P/LbaFqf2P3mbWdZzg3uJ69uzp/xXazGwDeIjSzMwqyQnOzMwqyQnOzMwqyQnOzMwqyQnOzMwqyQnOzMwqyQnOzMwqyQnOzMwqyQnOzMwqyQnOzMwqqdQEJ2mMpLmS5kma1GD5aEmzJK2WdFJh/l6SZkqaLWmOpHMa1L1N0iNlxmtmZtVV2t+ilNQdmAIcA7QB90u6LSIeLRR7FpgAfKau+hLgkIhYKWl74JFcd3Fu+4PAy2XFamZm1VfmHdwIYF5EzI+IVcBU4IRigYhYEBEPAWvq5q+KiJV5cttiXDnh/SPw5RJjNTOziiszwfUDFham2/K8pkjaU9JDuY1LandvwEXA5cArndQ/W1KrpFb/1zJmZlZmglODeU3/L50RsTAiDgT2Bs6QtIekYcDeEXFrE/WvjYiWiGjp27dv81GbmVkllfn/wbUBexam+wOL2ynbrohYLGkOMAroCxwkaQEp1t0l3RMRh298uGZmVmVl3sHdD+wjaaCkbYBTgNuaqSipv6Te+eedgUOBuRFxdUS8MyIGAO8DnnByMzOzZpSW4CJiNXAucCfwGHBzRMyRNFnSOABJ75HUBowHvpXv1AD2B2ZIehC4F7gsIh4uKzYzM9v6KKLpx2RbjJaWlmhtbe3qMMzMtiiSZkZES1fHURb/JRMzM6skJzgzM6skJzgzM6skJzgzM6skJzgzM6skJzgzM6skJzgzM6skJzgzM6skJzgzM6skJzgzM6skJzgzM6skJzgzM6skJzgzM6skJzgzM6skJzgzM6skJzgzM6skJzgzM6skJzgzM6skJzgzM6ukUhOcpDGS5kqaJ2lSg+WjJc2StFrSSYX5e0maKWm2pDmSzsnzt5N0u6TH8/yLy4zXzMyqq7QEJ6k7MAU4HhgEnCppUF2xZ4EJwI/q5i8BDomIYcB7gUmS3pmXXRYR+wHDgUMlHV9WzGZmVl09SmxrBDAvIuYDSJoKnAA8WisQEQvysjXFihGxqjC5LTnxRsQrwN21MpJmAf1LjNnMzCqqzCHKfsDCwnRbntcUSXtKeii3cUlELK5b3gcYC0wvIVYzM6u4MhOcGsyLZitHxMKIOBDYGzhD0h5rG5Z6AD8GrqjdIa6zculsSa2SWpcuXbqeoZuZWdWUmeDagD0L0/2Bxe2UbVe+c5sDjCrMvhZ4MiK+0UG9ayOiJSJa+vbtu76rNTOziikzwd0P7CNpoKRtgFOA25qpKKm/pN75552BQ4G5efrLwE7A+SXGamZmFVdagouI1cC5wJ3AY8DNETFH0mRJ4wAkvUdSGzAe+JakObn6/sAMSQ8C95LenHxYUn/gc6S3MmflXyP4ZFkxm5lZdSmi6cdkW4yWlpZobW3t6jDMzLYokmZGREtXx1EW/yUTMzOrJCc4MzOrJCc4MzOrJCc4MzOrJCc4MzOrJCc4MzOrJCc4MzOrJCc4MzOrJCc4MzOrJCc4MzOrJCc4MzOrJCc4MzOrJCc4MzOrJCc4MzOrJCc4MzOrpEr+f3CSlgLPdHUcG2A34IWuDmIz29q2eWvbXvA2b0n2ioi+XR1EWSqZ4LZUklqr9J8NNmNr2+atbXvB22xdx0OUZmZWSU5wZmZWSU5wby3XdnUAXWBr2+atbXvB22xdxM/gzMysknwHZ2ZmleQEt5lJ2kXSXZKezP/u3E65M3KZJyWd0WD5bZIe2fQRb5yN2V5J20m6XdLjkuZIunjzRr9+JI2RNFfSPEmTGizfVtJNefkMSQMKyz6b58+VdNzmjHtjbOg2SzpG0kxJD+d/j9zcsW+ojTnOefn/kPSypM9srpi3WhHhz2b8AJcCk/LPk4BLGpTZBZif/905/7xzYfkHgR8Bj3T19mzK7QW2A47IZbYBfgMc39Xb1M52dgeeAv5njvVBYFBdmYnANfnnU4Cb8s+DcvltgYG5ne5dvU2beJuHA+/MPw8GFnX19mzqbS4svwWYBnymq7en6h/fwW1+JwDfyz9/DzixQZnjgLsi4qWI+DNwFzAGQNL2wD8CX94MsZZhg7c3Il6JiLsBImIVMAvovxli3hAjgHkRMT/HOpW07UXFffEfwFGSlOdPjYiVEfE0MC+391a3wdscEQ9ExOI8fw7QS9K2myXqjbMxxxlJJ5Iu4OZspni3ak5wm98eEbEEIP+7e4My/YCFhem2PA/gIuBy4JVNGWSJNnZ7AZDUBxgLTN9EcW6sTrehWCYiVgPLgV2brPtWtDHbXPQh4IGIWLmJ4izTBm+zpLcB/wJ8aTPEaUCPrg6giiT9F/D2Bos+12wTDeaFpGHA3hFxQf24flfaVNtbaL8H8GPgioiYv/4RbhYdbkMnZZqp+1a0MducFkoHAJcAx5YY16a0Mdv8JeDrEfFyvqGzTcwJbhOIiKPbWybpOUnviIglkt4BPN+gWBtweGG6P3APMBI4SNIC0rHbXdI9EXE4XWgTbm/NtcCTEfGNEsLdVNqAPQvT/YHF7ZRpy0l7J+ClJuu+FW3MNiOpP3ArcHpEPLXpwy3Fxmzze4GTJF0K9AHWSFoREVdt+rC3Ul39EHBr+wBf5c0vXVzaoMwuwNOkFy12zj/vUldmAFvGSyYbtb2kZ423AN26els62c4epGcrA3nj5YMD6sp8mje/fHBz/vkA3vySyXy2jJdMNmab++TyH+rq7dhc21xX5ov4JZNNf7y6OoCt7UN6/jAdeDL/WzuRtwDfLpT7OOllg3nAmQ3a2VIS3AZvL+nqOIDHgNn588mu3qYOtvVvgSdIb9l9Ls+bDIzLP/civT03D/gj8D8LdT+X683lLfqmaJnbDHwe+GvhuM4Gdu/q7dnUx7nQhhPcZvj4L5mYmVkl+S1KMzOrJCc4MzOrJCc4MzOrJCc4MzOrJCc4MzOrJCc4MzOrJCc4MzOrJCc4MzOrpP8PbGaX7wQm/nYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "rf, = plt.plot(RF_scores, color='b')\n",
    "\n",
    "plt.legend([rf],\n",
    "           [\"Random Forest\"],\n",
    "           bbox_to_anchor=(0, .4, .5, 0))\n",
    "\n",
    "plt.title('Test scores as RMSLE with hyperparameter optimization',\n",
    "          x=.5, y=1.1, fontsize=\"15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "54lkC72t-coi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13819998404466372]\n",
      "Random Forest generalization score: 0.13819998404466372\n"
     ]
    }
   ],
   "source": [
    "print(RF_scores)\n",
    "print('Random Forest generalization score: {0}'.format(np.mean(RF_scores)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "House_Prices.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
