{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "t6W7PQysnFNx",
    "outputId": "4357a8cb-3582-4165-c771-e8156bcb26fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fancyimpute import IterativeImputer\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold, ParameterGrid, ParameterSampler\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "train = pd.read_csv('https://raw.githubusercontent.com/casperbh96/house-price-prediction/master/Experimental/data/train.csv')\n",
    "test = pd.read_csv('https://raw.githubusercontent.com/casperbh96/house-price-prediction/master/Experimental/data/test.csv')\n",
    "\n",
    "def fill_ii(df):\n",
    "    df_filled_ii = pd.DataFrame(IterativeImputer().fit_transform(df.values))\n",
    "    df_filled_ii.columns = df.columns\n",
    "    df_filled_ii.index = df.index\n",
    "\n",
    "    return df_filled_ii\n",
    "\n",
    "def data_engineering(train, test):\n",
    "    train = train.drop(train.index[0])\n",
    "    \n",
    "    cc_data = pd.concat([train, test], sort=True)\n",
    "    cc_data = cc_data.drop(['Id', 'SalePrice','Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature'], axis=1)\n",
    "    \n",
    "    train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n",
    "    y = train['SalePrice']\n",
    "    \n",
    "    cc_data = pd.get_dummies(cc_data, prefix_sep='_')\n",
    "    \n",
    "    cc_data = fill_ii(cc_data)\n",
    "    \n",
    "    X_train = cc_data[:train.shape[0]]\n",
    "    X_test = cc_data[train.shape[0]:]\n",
    "    \n",
    "    return X_train,X_test,y\n",
    "\n",
    "X,X_test,y = data_engineering(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l3gXfOMgoODT"
   },
   "outputs": [],
   "source": [
    "class NestedCV():\n",
    "    '''A general class to handle nested cross-validation for any estimator that\n",
    "    implements the scikit-learn estimator interface.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : estimator\n",
    "        The estimator implements scikit-learn estimator interface.\n",
    "\n",
    "    params_grid : dict\n",
    "        The dict contains hyperparameters for model.\n",
    "\n",
    "    outer_kfolds : int\n",
    "        Number of outer K-partitions in KFold\n",
    "\n",
    "    inner_kfolds : int\n",
    "        Number of inner K-partitions in KFold\n",
    "\n",
    "    cv_options: dict, default = {}\n",
    "        Nested CV Options, check docs for details.\n",
    "\n",
    "        metric : callable from sklearn.metrics, default = mean_squared_error\n",
    "            A scoring metric used to score each model\n",
    "\n",
    "        metric_score_indicator_lower : boolean, default = True\n",
    "            Choose whether lowe score is better for the metric calculation or hight score is better, `True` means lower score is better.\n",
    "\n",
    "        sqrt_of_score : boolean, default = False\n",
    "            Whether or not if the square root should be taken of score\n",
    "\n",
    "        randomized_search : boolean, default = True\n",
    "            Whether to use gridsearch or randomizedsearch from sklearn\n",
    "\n",
    "        randomized_search_iter : int, default = 10\n",
    "            Number of iterations for randomized search\n",
    "\n",
    "        recursive_feature_elimination : boolean, default = False\n",
    "            Whether to do feature elimination\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model, params_grid, outer_kfolds, inner_kfolds, cv_options={}):\n",
    "        self.model = model\n",
    "        self.params_grid = params_grid\n",
    "        self.outer_kfolds = outer_kfolds\n",
    "        self.inner_kfolds = inner_kfolds\n",
    "        self.metric = cv_options.get('metric', mean_squared_error)\n",
    "        self.metric_score_indicator_lower = cv_options.get(\n",
    "            'metric_score_indicator_lower', True)\n",
    "        self.sqrt_of_score = cv_options.get('sqrt_of_score', False)\n",
    "        self.randomized_search = cv_options.get('randomized_search', True)\n",
    "        self.randomized_search_iter = cv_options.get(\n",
    "            'randomized_search_iter', 10)\n",
    "        self.recursive_feature_elimination = cv_options.get(\n",
    "            'recursive_feature_elimination', False)\n",
    "        self.outer_scores = []\n",
    "        self.best_params = {}\n",
    "        self.best_inner_score_list = []\n",
    "        self.variance = []\n",
    "\n",
    "    # to check if use sqrt_of_score and handle the different cases\n",
    "    def _transform_score_format(self, scoreValue):\n",
    "        if self.sqrt_of_score:\n",
    "            return np.sqrt(scoreValue)\n",
    "        return scoreValue\n",
    "\n",
    "    # to convert array of dict to dict with array values, so it can be used as params for parameter tuning\n",
    "    def _score_to_best_params(self, best_inner_params_list):\n",
    "        params_dict = {}\n",
    "        for best_inner_params in best_inner_params_list:\n",
    "            for key, value in best_inner_params.items():\n",
    "                if key in params_dict:\n",
    "                    if value not in params_dict[key]:\n",
    "                        params_dict[key].append(value)\n",
    "                else:\n",
    "                    params_dict[key] = [value]\n",
    "        return params_dict\n",
    "\n",
    "    # a method to handle  recursive feature elimination\n",
    "    def _fit_recursive_feature_elimination(self, best_inner_params, X_train_outer, y_train_outer, X_test_outer):\n",
    "        print('\\nRunning recursive feature elimination for outer loop... (SLOW)')\n",
    "        # K-fold (inner_kfolds) recursive feature elimination\n",
    "        rfe = RFECV(estimator=self.model, min_features_to_select=20,\n",
    "                    scoring='neg_mean_squared_error', cv=self.inner_kfolds, n_jobs=-1)\n",
    "        rfe.fit(X_train_outer, y_train_outer)\n",
    "\n",
    "        # Assign selected features to data\n",
    "        print('Best number of features was: {0}'.format(rfe.n_features_))\n",
    "        X_train_outer_rfe = rfe.transform(X_train_outer)\n",
    "        X_test_outer_rfe = rfe.transform(X_test_outer)\n",
    "\n",
    "        # Train model with best inner parameters on the outer split\n",
    "        self.model.set_params(**best_inner_params)\n",
    "        self.model.fit(X_train_outer_rfe, y_train_outer)\n",
    "        return self.model.predict(X_test_outer_rfe)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''A method to fit nested cross-validation \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas dataframe (rows, columns)\n",
    "            Training dataframe, where rows is total number of observations and columns\n",
    "            is total number of features\n",
    "    \n",
    "        y : pandas dataframe\n",
    "            Output dataframe, also called output variable. y is what you want to predict.\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        It will not return directly the values, but it's accessable from the class object it self.\n",
    "        You should be able to access:\n",
    "        \n",
    "        variance\n",
    "            Model variance by numpy.var()\n",
    "            \n",
    "        outer_scores \n",
    "            Outer score List.\n",
    "            \n",
    "        best_inner_score_list \n",
    "            Best inner scores for each outer loop\n",
    "            \n",
    "        best_params \n",
    "            All best params from each inner loop cumulated in a dict\n",
    "            \n",
    "        best_inner_params_list \n",
    "            Best inner params for each outer loop as an array of dictionaries\n",
    "        '''\n",
    "    \n",
    "        print('\\n{0} <-- Running this model now'.format(type(self.model).__name__))\n",
    "        outer_cv = KFold(n_splits=self.outer_kfolds, shuffle=True)\n",
    "        inner_cv = KFold(n_splits=self.inner_kfolds, shuffle=True)\n",
    "        model = self.model\n",
    "    \n",
    "        outer_scores = []\n",
    "        variance = []\n",
    "        best_inner_params_list = []  # Change both to by one thing out of key-value pair\n",
    "        best_inner_score_list = []\n",
    "    \n",
    "        # Split X and y into K-partitions to Outer CV\n",
    "        for (i, (train_index, test_index)) in enumerate(outer_cv.split(X, y)):\n",
    "            print('\\n{0}/{1} <-- Current outer fold'.format(i+1, self.outer_kfolds))\n",
    "            X_train_outer, X_test_outer = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train_outer, y_test_outer = y.iloc[train_index], y.iloc[test_index]\n",
    "            best_inner_params = {}\n",
    "            best_inner_score = None\n",
    "    \n",
    "            # Split X_train_outer and y_train_outer into K-partitions to be inner CV\n",
    "            for (j, (train_index_inner, test_index_inner)) in enumerate(inner_cv.split(X_train_outer, y_train_outer)):\n",
    "                print('\\n\\t{0}/{1} <-- Current inner fold'.format(j+1, self.inner_kfolds))\n",
    "                X_train_inner, X_test_inner = X_train_outer.iloc[\n",
    "                    train_index_inner], X_train_outer.iloc[test_index_inner]\n",
    "                y_train_inner, y_test_inner = y_train_outer.iloc[\n",
    "                    train_index_inner], y_train_outer.iloc[test_index_inner]\n",
    "    \n",
    "                # Run either RandomizedSearch or GridSearch for input parameters\n",
    "                for param_dict in ParameterSampler(param_distributions=self.params_grid, \n",
    "                                                   n_iter=self.randomized_search_iter) if (self.randomized_search) else (\n",
    "                                                           ParameterGrid(param_grid=self.params_grid)):\n",
    "                    # Set parameters, train model on inner split, predict results.\n",
    "                    if(type(self.model).__name__ == 'KerasRegressor'):\n",
    "                        with tf.device('/gpu:0'):\n",
    "                          model.set_params(**param_dict)\n",
    "                          model.fit(X_train_inner, y_train_inner)\n",
    "                    else:\n",
    "                      model.set_params(**param_dict)\n",
    "                      model.fit(X_train_inner, y_train_inner)\n",
    "                    \n",
    "                    \n",
    "                    inner_pred = model.predict(X_test_inner)\n",
    "                    inner_grid_score = self.metric(y_test_inner, inner_pred)\n",
    "                    current_inner_score_value = best_inner_score\n",
    "                    # Find best score and corresponding best grid\n",
    "                    if(best_inner_score is not None):\n",
    "                        if(self.metric_score_indicator_lower and best_inner_score > inner_grid_score):\n",
    "                            best_inner_score = self._transform_score_format(inner_grid_score)\n",
    "                            \n",
    "                        elif (not self.metric_score_indicator_lower and best_inner_score < inner_grid_score):\n",
    "                            best_inner_score = self._transform_score_format(inner_grid_score)\n",
    "                    else:\n",
    "                        best_inner_score = self._transform_score_format(inner_grid_score)\n",
    "                        current_inner_score_value = best_inner_score+1  # first time random thing\n",
    "                        \n",
    "                    # Update best_inner_grid once rather than calling it under each if statement\n",
    "                    if(current_inner_score_value is not None and current_inner_score_value != best_inner_score):\n",
    "                        best_inner_params = param_dict\n",
    "    \n",
    "            best_inner_params_list.append(best_inner_params)\n",
    "            best_inner_score_list.append(best_inner_score)\n",
    "    \n",
    "            if self.recursive_feature_elimination:\n",
    "                pred = self._fit_recursive_feature_elimination(\n",
    "                    best_inner_params, X_train_outer, y_train_outer, X_test_outer)\n",
    "            else:\n",
    "                # Train model with best inner parameters on the outer split\n",
    "                model.set_params(**best_inner_params)\n",
    "                model.fit(X_train_outer, y_train_outer)\n",
    "                pred = model.predict(X_test_outer)\n",
    "    \n",
    "            outer_scores.append(self._transform_score_format(\n",
    "                self.metric(y_test_outer, pred)))\n",
    "    \n",
    "            # Append variance\n",
    "            variance.append(np.var(pred, ddof=1))\n",
    "    \n",
    "            print('\\nResults for outer fold:\\nBest inner parameters was: {0}'.format(\n",
    "                best_inner_params_list[i]))\n",
    "            print('Outer score: {0}'.format(outer_scores[i]))\n",
    "            print('Inner score: {0}'.format(best_inner_score_list[i]))\n",
    "    \n",
    "        self.variance = variance\n",
    "        self.outer_scores = outer_scores\n",
    "        self.best_inner_score_list = best_inner_score_list\n",
    "        self.best_params = self._score_to_best_params(best_inner_params_list)\n",
    "        self.best_inner_params_list = best_inner_params_list\n",
    "\n",
    "    # Method to show score vs variance chart. You can run it only after fitting the model.\n",
    "    def score_vs_variance_plot(self):\n",
    "        # Plot score vs variance\n",
    "        plt.figure()\n",
    "        plt.subplot(211)\n",
    "\n",
    "        variance_plot, = plt.plot(self.variance, color='b')\n",
    "        score_plot, = plt.plot(self.outer_scores, color='r')\n",
    "\n",
    "        plt.legend([variance_plot, score_plot],\n",
    "                   [\"Variance\", \"Score\"],\n",
    "                   bbox_to_anchor=(0, .4, .5, 0))\n",
    "\n",
    "        plt.title(\"{0}: Score VS Variance\".format(type(self.model).__name__),\n",
    "                  x=.5, y=1.1, fontsize=\"15\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NestedCV parameters\n",
    "NUM_TRIALS = 50\n",
    "outerFolds = 5\n",
    "innerFolds = 5\n",
    "\n",
    "models_to_run = [xgb.XGBRegressor()]\n",
    "models_param_grid = [\n",
    "                    { # 3rd param grid, corresponding to XGBRegressor\n",
    "                            'learning_rate': [0.05],\n",
    "                            'colsample_bytree': np.linspace(0.3, 0.5),\n",
    "                            'n_estimators': [100,200,300,400,500,600,700,800,900,1000],\n",
    "                            'reg_alpha' : (1,1.2),\n",
    "                            'reg_lambda' : (1,1.2,1.4)\n",
    "                    }\n",
    "                    ]\n",
    "XGB_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "0pKVdTkjogUk",
    "outputId": "cd9796fc-a54f-4f49-e747-fe3f1f48945f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 0 / 50\n",
      "\n",
      "XGBRegressor <-- Running this model now\n",
      "\n",
      "1/5 <-- Current outer fold\n",
      "\n",
      "\t1/5 <-- Current inner fold\n",
      "\n",
      "\t2/5 <-- Current inner fold\n"
     ]
    }
   ],
   "source": [
    "for trial in range(NUM_TRIALS):\n",
    "    print('Running {0} / {1}'.format(trial,NUM_TRIALS))\n",
    "    for i,model in enumerate(models_to_run):\n",
    "        nested_CV_search = NestedCV(model=model, params_grid=models_param_grid[i], outer_kfolds=outerFolds, inner_kfolds=innerFolds, \n",
    "                          cv_options={'sqrt_of_score':True, 'randomized_search_iter':30})\n",
    "        nested_CV_search.fit(X=X,y=y)\n",
    "        model_param_grid = nested_CV_search.best_params\n",
    "        print('\\nCumulated best parameter grids was:\\n{0}'.format(model_param_grid))\n",
    "        \n",
    "        gscv = GridSearchCV(estimator=model,param_grid=model_param_grid,scoring='neg_mean_squared_error',cv=5, n_jobs=-1)\n",
    "        gscv.fit(X,y)\n",
    "        \n",
    "        print('\\nFitting with optimal parameters:\\n{0}'.format(gscv.best_params_))\n",
    "        gscv.predict(X_test)\n",
    "        score = np.sqrt(-gscv.best_score_)\n",
    "        \n",
    "        if(type(model).__name__ == 'KerasRegressor'):\n",
    "            NN_scores.append(score)\n",
    "        elif(type(model).__name__ == 'RandomForestRegressor'):\n",
    "            RF_scores.append(score)\n",
    "        elif(type(model).__name__ == 'XGBRegressor'):\n",
    "            XGB_scores.append(score)\n",
    "        \n",
    "        print('\\nFinal score for {0} was {1}'.format(type(model).__name__,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "xgb, = plt.plot(XGB_scores, color='r')\n",
    "\n",
    "plt.legend([xgb],\n",
    "           [\"XGBoost\"],\n",
    "           bbox_to_anchor=(0, .4, .5, 0))\n",
    "\n",
    "plt.title('Test scores as RMSLE with hyperparameter optimization',\n",
    "          x=.5, y=1.1, fontsize=\"15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "54lkC72t-coi"
   },
   "outputs": [],
   "source": [
    "print(XGB_scores)\n",
    "print('XG boost generalization score: {0}'.format(np.mean(XGB_scores)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "House_Prices.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
